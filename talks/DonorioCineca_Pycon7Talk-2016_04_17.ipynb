{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/welcome.jpeg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Automatizzare la creazione e la gestione di un cluster di containers su cloud\n",
    "\n",
    "*#Pycon7* \n",
    "\n",
    "<small>Slides disponibili a http://j.mp/pycon7-cineca</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sottotitolo*\n",
    "\n",
    "> La storia del nostro ambiente di corsi Python basato su Openstack, Docker, Anaconda e Jupyter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Logo pycon 7 https://odoo-community.org/website/image/ir.attachment/26982_7b70ca1/datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "Io => ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table,td,tr,th {border:none!important}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table,td,tr,th {border:none!important}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<style type=\"text/css\" scoped>\n",
    "table,td,tr,th {border:none!important}\n",
    "</style>\n",
    "<table>\n",
    "<tr> <td colspan=2 align=center style='border: 0px;'>\n",
    "<center>\n",
    "<h1>\n",
    "Chi sono\n",
    "</h1>\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "\n",
    "<td>\n",
    "\n",
    "<br>\n",
    "<img src='https://pbs.twimg.com/profile_images/588326878697619456/8lAb7yJ8.jpg' width=400>\n",
    "\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "<ul>\n",
    "<li>\n",
    "Paolo [p.donoriodemeo@cineca.it](mailto:p.donoriodemeo@cineca.it) \n",
    "</li>\n",
    "<li>\n",
    "Twitter [@paolodonorio](https://twitter.com/paolodonorio)\n",
    "</li>\n",
    "<li>\n",
    "GitHub [@pdonorio](https://github.com/pdonorio), \n",
    "<br>&nbsp; [@cineca-scai](https://github.com/cineca-scai), [@EUDAT-B2STAGE](https://github.com/EUDAT-B2STAGE)\n",
    "</li>\n",
    "<li>Pythonista: 4 anni &hearts; con Python</li> \n",
    "<li>Secondo anno di seguito al Pycon</li> \n",
    "<li>Prima volta che presento (al Pycon)</li>\n",
    "</ul>\n",
    "</td>\n",
    "\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<h3> CINECA - Dipartimento SCAI </h3>\n",
    "<br>\n",
    "<i>Supporto alla ricerca e collaborazioni</i>\n",
    "<img src='http://www.hpc.cineca.it/sites/all/themes/scai/logo.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src='https://raw.githubusercontent.com/cineca-scai/lectures/sns/material/DAY_01/images/cineca.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Macchine di calcolo\n",
    "\n",
    "* *FERMI*\n",
    "    - BlueGene/Q - 163.840 cores\n",
    "* *GALILEO*\n",
    "    - IBM NeXtScale - 8.256 cores\n",
    "* *PICO*\n",
    "    - Architettura ibrida - 1.320+ cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* *MARCONI*\n",
    "    - http://www.cineca.it/it/news/supercomputer-marconi (13/04/2016 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Richiesta risorse per il tuo progetto\n",
    "\n",
    "* **ISCRA** Nazionale \n",
    "* **PRACE** Europeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Corsi su High Performance Computing\n",
    "\n",
    "* Unix, C, C++, Fortran\n",
    "* MPI, OpenMP\n",
    "* Python\n",
    "\n",
    "http://www.cineca.it/it/content/elenco-corsi-hpc-2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "Io => Corso Python => ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Python for computing science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 2013: docente per il corso\n",
    "- Introduzione al linguaggio\n",
    "- PyData: Numpy, Scipy, Matplotlib, Cython, f2py\n",
    "- Slides in powerpoint\n",
    "- *Canopy* su Pc Windows per corsi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The good\n",
    "\n",
    "- Linguaggio con curva veloce di apprendimento\n",
    "- Spiegazione funzionale "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## The bad\n",
    "\n",
    "- Persone con proprio laptop: setup e versioni\n",
    "- Spiegare dove salvare i files per eseguirli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## The ugly\n",
    "\n",
    "- Shell (cmd) di windows\n",
    "- Copia/incolla template e soluzioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Lo studente medio di un nostro corso Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img src='http://www.warnerchannel.com/res/series/tbbt/character/per_howard_wolowitz.jpg' width=300>\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<ul>\n",
    "<li>\n",
    "Dall'accademia: laureando, dottorando, ricercatore\n",
    "</li><li>\n",
    "Scarse nozioni di programmazione classica\n",
    "</li><li>\n",
    "Qualche codice di scripting (quasi certamente R)\n",
    "</li><li>\n",
    "Necessita librerie con funzioni scientifiche\n",
    "</li><li>\n",
    "Vuole plot dei dati analizzati\n",
    "</li><li>\n",
    "Materiale con molti esempi pratici\n",
    "</li><li>\n",
    "Istruzioni su come installare in locale un ambiente analogo al cluster di calcolo\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "Io => Corso Python => Docker (1.2) => ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Primi test con la creazione di API endpoint usando Flask\n",
    "* Replicare la stessa macchina virtuale da zero tra sviluppo e produzione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**stackoverflow**: [Should i use Vagrant or Docker](http://stackoverflow.com/questions/16647069/should-i-use-vagrant-or-docker-for-creating-an-isolated-environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Contenitori e implementazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"http://danstroot.com/assets/img/dockervsvm.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Un concetto utilizzato più di dieci anni fa\n",
    "    * LXC\n",
    "- Virtualizzazione su specifiche del Kernel \n",
    "    * CGROUPS (users, disk)\n",
    "    * NameSpaces (processes)\n",
    "- Orientato a performance vicine all'hardware\n",
    "    * Limitata a distribuzioni UNIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> **What's LXC?**\n",
    "\n",
    "> LXC is a userspace interface for the Linux kernel containment features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Quali alternative abbiamo?\n",
    "\n",
    "* LXC\n",
    "    - [LXD](https://linuxcontainers.org/lxd/introduction/)\n",
    "    - [Virtuozzo](https://virtuozzo.com/)\n",
    "    - [LVE](http://docs.cloudlinux.com/index.html?understanding_lve.html)\n",
    "* Docker\n",
    "* CoreOs [rkt](https://coreos.com/rkt/)\n",
    "* HPC [Shifter](http://j.mp/266N5hE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## L'ecosistema Docker\n",
    "\n",
    "<img src=\"http://j.mp/1QUUrKp\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> On March 13, 2014, with the release of version 0.9, Docker dropped LXC as the default execution environment and replaced it with its own libcontainer library written in the Go programming language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Docker engine\n",
    "\n",
    "<img src='https://denibertovic.com/talks/supercharge-development-env-using-docker/img/what_is_docker.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Ha reso facile l'utilizzo dei container\n",
    "* Basato su un linguaggio a basso livello moderno (chiamato [GO](https://golang.org/), ideato da Google)\n",
    "* Implementata su libcontainers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Docker client: i comandi da shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "# Extra clean to show examples\n",
    "docker rm -f $(docker ps -a -q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How docker commands work:\n",
    "\n",
    "```bash\n",
    "# Generic client\n",
    "docker DOCKER_COMMAND <options> \n",
    "\n",
    "# Run command\n",
    "docker run <options> IMAGE BASH_COMMAND\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> Execute a container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin   dev  home  lib64\tmnt  proc  run\t srv  tmp  var\r\n",
      "boot  etc  lib\t media\topt  root  sbin  sys  usr\r\n"
     ]
    }
   ],
   "source": [
    "! docker run -it ubuntu:15.10 ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> Launch a database server on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0a5ab0ef0b6aa9012f1ade80cf0ead4c814df3a307c2b00504ecb946bc6b0e7c\r\n"
     ]
    }
   ],
   "source": [
    "! docker run \\\n",
    "    --detach \\\n",
    "    --name mydb \\\n",
    "    -e POSTGRES_USER=paulie \\\n",
    "    -e POSTGRES_PASSWORD=mypass \\\n",
    "    -e POSTGRES_DB=justadb \\\n",
    "    postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Congelare lo stato in stand-by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mydb\r\n"
     ]
    }
   ],
   "source": [
    "! docker stop mydb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mydb\r\n"
     ]
    }
   ],
   "source": [
    "! docker start mydb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Esegui un comando su un container Docker che è attualmente in esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apt   exim4\t   insserv    misc  postgresql\tsystemd  update-rc.d  xml-core\r\n",
      "dpkg  initscripts  logrotate  pam   sgml-base\tucf\t urandom\r\n"
     ]
    }
   ],
   "source": [
    "! docker exec -it mydb ls /var/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mpostfix\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "# Notare che la stessa directory nel mio computer ha un contenuto diverso\n",
    "! ls /var/lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Containers and processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "! docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "! docker ps -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Docker Networking\n",
    "\n",
    "Un esempio di come le cose evolvono"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Specificare manualmente il link tra due container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 List of databases\r\n",
      "   Name    |  Owner   | Encoding |  Collate   |   Ctype    |   Access privileges\r\n",
      "   \r\n",
      "-----------+----------+----------+------------+------------+--------------------\r\n",
      "---\r\n",
      " justadb   | postgres | UTF8     | en_US.utf8 | en_US.utf8 | \r\n",
      " postgres  | postgres | UTF8     | en_US.utf8 | en_US.utf8 | \r\n",
      " template0 | postgres | UTF8     | en_US.utf8 | en_US.utf8 | =c/postgres        \r\n",
      "  +\r\n",
      "           |          |          |            |            | postgres=CTc/postgr\r\n",
      "es\r\n",
      " template1 | postgres | UTF8     | en_US.utf8 | en_US.utf8 | =c/postgres        \r\n",
      "  +\r\n",
      "           |          |          |            |            | postgres=CTc/postgr\r\n",
      "es\r\n",
      "(4 rows)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! docker run -it --link mydb:server -e PGPASSWORD=mypass postgres \\\n",
    "    psql \\\n",
    "    -h server \\\n",
    "    -U paulie \\\n",
    "    -d justadb \\\n",
    "    -c '\\l' #list databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: Error response from daemon: Could not get container for acontainerthatdoesnotexist.\r\n",
      "See 'docker run --help'.\r\n"
     ]
    }
   ],
   "source": [
    "! docker run -it --link acontainerthatdoesnotexist:linked ubuntu:15.10 bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Nuova modalità (dalla versione 1.9+): crea e gestisci le reti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0ad7eee02bddce30b11a4614551c276ac225a0ae764e5fd50843b29e43b1de0\r\n"
     ]
    }
   ],
   "source": [
    "! docker network create --driver=bridge mynet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfc1d47c46c25d5ea533fcea6002051dc7be40dd9bd7fd7e6dc1beca764cd171\r\n"
     ]
    }
   ],
   "source": [
    "! docker run -d -p 80:80 --net=mynet clue/adminer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now go to [localhost](http://local.docker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c4ee20ec34872d3c7d27b291ae178e51f86d68ff38c75617af1c4f01bb02200c\r\n"
     ]
    }
   ],
   "source": [
    "# Add a linked database on a running container (adminer)\n",
    "! docker run -d --name mydb2 \\\n",
    "    --net=mynet \\\n",
    "    -e POSTGRES_USER=paulie \\\n",
    "    -e POSTGRES_PASSWORD=mypass \\\n",
    "    -e POSTGRES_DB=justadb \\\n",
    "    postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Docker images\n",
    "\n",
    "Quello che fanno i tuoi container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find image 'alpine:latest' locally\n",
      "latest: Pulling from library/alpine\n",
      "\u001b[0B\n",
      "\u001b[1BDigest: sha256:9cacb71397b640eca97488cf08582ae4e4068513101088e9f96c9814bfda95e0\n",
      "Status: Downloaded newer image for alpine:latest\n",
      "BusyBox v1.24.1 (2015-12-16 08:00:02 GMT) multi-call binary.\n",
      "\n",
      "Usage: wget [-csq] [-O FILE] [-Y on/off] [-P DIR] [-U AGENT] [-T SEC] URL...\n",
      "\n",
      "Retrieve files via HTTP or FTP\n",
      "\n",
      "\t-s\tSpider mode - only check file existence\n",
      "\t-c\tContinue retrieval of aborted transfer\n",
      "\t-q\tQuiet\n",
      "\t-P DIR\tSave to DIR (default .)\n",
      "\t-T SEC\tNetwork read timeout is SEC seconds\n",
      "\t-O FILE\tSave to FILE ('-' for stdout)\n",
      "\t-U STR\tUse STR for User-Agent header\n",
      "\t-Y\tUse proxy ('on' or 'off')\n"
     ]
    }
   ],
   "source": [
    "! docker run -it alpine wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: Error response from daemon: Container command 'curl' not found or does not exist..\n"
     ]
    }
   ],
   "source": [
    "! docker run -it alpine curl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Costruire una propria immagine Docker è molto semplice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM alpine\n",
    "RUN apk update && apk upgrade\n",
    "RUN apk add curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon 644.1 kB\n",
      "Step 1 : FROM alpine\n",
      " ---> d7a513a663c1\n",
      "Step 2 : RUN apk update && apk upgrade\n",
      " ---> Running in 7adcaf0869b9\n",
      "fetch http://dl-cdn.alpinelinux.org/alpine/v3.3/main/x86_64/APKINDEX.tar.gz\n",
      "fetch http://dl-cdn.alpinelinux.org/alpine/v3.3/community/x86_64/APKINDEX.tar.gz\n",
      "v3.3.3-24-g74309b7 [http://dl-cdn.alpinelinux.org/alpine/v3.3/main]\n",
      "v3.3.3-9-gfc38db2 [http://dl-cdn.alpinelinux.org/alpine/v3.3/community]\n",
      "OK: 5858 distinct packages available\n",
      "(1/2) Upgrading musl (1.1.12-r4 -> 1.1.12-r5)\n",
      "(2/2) Upgrading musl-utils (1.1.12-r4 -> 1.1.12-r5)\n",
      "Executing busybox-1.24.1-r7.trigger\n",
      "OK: 5 MiB in 11 packages\n",
      " ---> 9f5786bf7fdc\n",
      "Removing intermediate container 7adcaf0869b9\n",
      "Step 3 : RUN apk add curl\n",
      " ---> Running in ead927c86bbe\n",
      "(1/4) Installing openssl (1.0.2g-r0)\n",
      "(2/4) Installing ca-certificates (20160104-r2)\n",
      "(3/4) Installing libssh2 (1.6.0-r1)\n",
      "(4/4) Installing curl (7.47.0-r0)\n",
      "Executing busybox-1.24.1-r7.trigger\n",
      "Executing ca-certificates-20160104-r2.trigger\n",
      "OK: 7 MiB in 15 packages\n",
      " ---> 5e2c0dd29103\n",
      "Removing intermediate container ead927c86bbe\n",
      "Successfully built 5e2c0dd29103\n"
     ]
    }
   ],
   "source": [
    "! docker build -t mydockerimage ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\r\n",
      "mydockerimage       latest              5e2c0dd29103        5 minutes ago       8.092 MB\r\n",
      "clue/adminer        latest              dbf8cf7a7ca7        2 days ago          223.4 MB\r\n",
      "postgres            latest              0f3af79d8673        11 days ago         265.7 MB\r\n",
      "ubuntu              15.10               4e3b13c8a266        11 days ago         136.3 MB\r\n",
      "alpine              latest              d7a513a663c1        2 weeks ago         4.798 MB\r\n"
     ]
    }
   ],
   "source": [
    "# Verifichiamo la nostra nuova immagine\n",
    "! docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: curl [options...] <url>\r\n",
      "Options: (H) means HTTP/HTTPS only, (F) means FTP only\r\n",
      "     --anyauth       Pick \"any\" authentication method (H)\r\n",
      " -a, --append        Append to target file when uploading (F/SFTP)\r\n",
      "     --basic         Use HTTP Basic Authentication (H)\r\n",
      "     --cacert FILE   CA certificate to verify peer against (SSL)\r\n",
      "     --capath DIR    CA directory to verify peer against (SSL)\r\n",
      " -E, --cert CERT[:PASSWD]  Client certificate file and password (SSL)\r\n",
      "     --cert-status   Verify the status of the server certificate (SSL)\r\n",
      "     --cert-type TYPE  Certificate file type (DER/PEM/ENG) (SSL)\r\n",
      "     --ciphers LIST  SSL ciphers to use (SSL)\r\n",
      "     --compressed    Request compressed response (using deflate or gzip)\r\n",
      " -K, --config FILE   Read config from FILE\r\n",
      "     --connect-timeout SECONDS  Maximum time allowed for connection\r\n",
      " -C, --continue-at OFFSET  Resumed transfer OFFSET\r\n",
      " -b, --cookie STRING/FILE  Read cookies from STRING/FILE (H)\r\n",
      " -c, --cookie-jar FILE  Write cookies to FILE after operation (H)\r\n",
      "     --create-dirs   Create necessary local directory hierarchy\r\n",
      "     --crlf          Convert LF to CRLF in upload\r\n",
      "     --crlfile FILE  Get a CRL list in PEM format from the given file\r\n",
      " -d, --data DATA     HTTP POST data (H)\r\n",
      "     --data-raw DATA  HTTP POST data, '@' allowed (H)\r\n",
      "     --data-ascii DATA  HTTP POST ASCII data (H)\r\n",
      "     --data-binary DATA  HTTP POST binary data (H)\r\n",
      "     --data-urlencode DATA  HTTP POST data url encoded (H)\r\n",
      "     --delegation STRING  GSS-API delegation permission\r\n",
      "     --digest        Use HTTP Digest Authentication (H)\r\n",
      "     --disable-eprt  Inhibit using EPRT or LPRT (F)\r\n",
      "     --disable-epsv  Inhibit using EPSV (F)\r\n",
      "     --dns-servers   DNS server addrs to use: 1.1.1.1;2.2.2.2\r\n",
      "     --dns-interface  Interface to use for DNS requests\r\n",
      "     --dns-ipv4-addr  IPv4 address to use for DNS requests, dot notation\r\n",
      "     --dns-ipv6-addr  IPv6 address to use for DNS requests, dot notation\r\n",
      " -D, --dump-header FILE  Write the headers to FILE\r\n",
      "     --egd-file FILE  EGD socket path for random data (SSL)\r\n",
      "     --engine ENGINE  Crypto engine (use \"--engine list\" for list) (SSL)\r\n",
      "     --expect100-timeout SECONDS How long to wait for 100-continue (H)\r\n",
      " -f, --fail          Fail silently (no output at all) on HTTP errors (H)\r\n",
      "     --false-start   Enable TLS False Start.\r\n",
      " -F, --form CONTENT  Specify HTTP multipart POST data (H)\r\n",
      "     --form-string STRING  Specify HTTP multipart POST data (H)\r\n",
      "     --ftp-account DATA  Account data string (F)\r\n",
      "     --ftp-alternative-to-user COMMAND  String to replace \"USER [name]\" (F)\r\n",
      "     --ftp-create-dirs  Create the remote dirs if not present (F)\r\n",
      "     --ftp-method [MULTICWD/NOCWD/SINGLECWD]  Control CWD usage (F)\r\n",
      "     --ftp-pasv      Use PASV/EPSV instead of PORT (F)\r\n",
      " -P, --ftp-port ADR  Use PORT with given address instead of PASV (F)\r\n",
      "     --ftp-skip-pasv-ip  Skip the IP address for PASV (F)\r\n",
      "     --ftp-pret      Send PRET before PASV (for drftpd) (F)\r\n",
      "     --ftp-ssl-ccc   Send CCC after authenticating (F)\r\n",
      "     --ftp-ssl-ccc-mode ACTIVE/PASSIVE  Set CCC mode (F)\r\n",
      "     --ftp-ssl-control  Require SSL/TLS for FTP login, clear for transfer (F)\r\n",
      " -G, --get           Send the -d data with a HTTP GET (H)\r\n",
      " -g, --globoff       Disable URL sequences and ranges using {} and []\r\n",
      " -H, --header LINE   Pass custom header LINE to server (H)\r\n",
      " -I, --head          Show document info only\r\n",
      " -h, --help          This help text\r\n",
      "     --hostpubmd5 MD5  Hex-encoded MD5 string of the host public key. (SSH)\r\n",
      " -0, --http1.0       Use HTTP 1.0 (H)\r\n",
      "     --http1.1       Use HTTP 1.1 (H)\r\n",
      "     --http2         Use HTTP 2 (H)\r\n",
      "     --ignore-content-length  Ignore the HTTP Content-Length header\r\n",
      " -i, --include       Include protocol headers in the output (H/F)\r\n",
      " -k, --insecure      Allow connections to SSL sites without certs (H)\r\n",
      "     --interface INTERFACE  Use network INTERFACE (or address)\r\n",
      " -4, --ipv4          Resolve name to IPv4 address\r\n",
      " -6, --ipv6          Resolve name to IPv6 address\r\n",
      " -j, --junk-session-cookies  Ignore session cookies read from file (H)\r\n",
      "     --keepalive-time SECONDS  Wait SECONDS between keepalive probes\r\n",
      "     --key KEY       Private key file name (SSL/SSH)\r\n",
      "     --key-type TYPE  Private key file type (DER/PEM/ENG) (SSL)\r\n",
      "     --krb LEVEL     Enable Kerberos with security LEVEL (F)\r\n",
      "     --libcurl FILE  Dump libcurl equivalent code of this command line\r\n",
      "     --limit-rate RATE  Limit transfer speed to RATE\r\n",
      " -l, --list-only     List only mode (F/POP3)\r\n",
      "     --local-port RANGE  Force use of RANGE for local port numbers\r\n",
      " -L, --location      Follow redirects (H)\r\n",
      "     --location-trusted  Like '--location', and send auth to other hosts (H)\r\n",
      "     --login-options OPTIONS  Server login options (IMAP, POP3, SMTP)\r\n",
      " -M, --manual        Display the full manual\r\n",
      "     --mail-from FROM  Mail from this address (SMTP)\r\n",
      "     --mail-rcpt TO  Mail to this/these addresses (SMTP)\r\n",
      "     --mail-auth AUTH  Originator address of the original email (SMTP)\r\n",
      "     --max-filesize BYTES  Maximum file size to download (H/F)\r\n",
      "     --max-redirs NUM  Maximum number of redirects allowed (H)\r\n",
      " -m, --max-time SECONDS  Maximum time allowed for the transfer\r\n",
      "     --metalink      Process given URLs as metalink XML file\r\n",
      "     --negotiate     Use HTTP Negotiate (SPNEGO) authentication (H)\r\n",
      " -n, --netrc         Must read .netrc for user name and password\r\n",
      "     --netrc-optional  Use either .netrc or URL; overrides -n\r\n",
      "     --netrc-file FILE  Specify FILE for netrc\r\n",
      " -:, --next          Allows the following URL to use a separate set of options\r\n",
      "     --no-alpn       Disable the ALPN TLS extension (H)\r\n",
      " -N, --no-buffer     Disable buffering of the output stream\r\n",
      "     --no-keepalive  Disable keepalive use on the connection\r\n",
      "     --no-npn        Disable the NPN TLS extension (H)\r\n",
      "     --no-sessionid  Disable SSL session-ID reusing (SSL)\r\n",
      "     --noproxy       List of hosts which do not use proxy\r\n",
      "     --ntlm          Use HTTP NTLM authentication (H)\r\n",
      "     --oauth2-bearer TOKEN  OAuth 2 Bearer Token (IMAP, POP3, SMTP)\r\n",
      " -o, --output FILE   Write to FILE instead of stdout\r\n",
      "     --pass PASS     Pass phrase for the private key (SSL/SSH)\r\n",
      "     --path-as-is    Do not squash .. sequences in URL path\r\n",
      "     --pinnedpubkey FILE/HASHES Public key to verify peer against (SSL)\r\n",
      "     --post301       Do not switch to GET after following a 301 redirect (H)\r\n",
      "     --post302       Do not switch to GET after following a 302 redirect (H)\r\n",
      "     --post303       Do not switch to GET after following a 303 redirect (H)\r\n",
      " -#, --progress-bar  Display transfer progress as a progress bar\r\n",
      "     --proto PROTOCOLS  Enable/disable PROTOCOLS\r\n",
      "     --proto-default PROTOCOL  Use PROTOCOL for any URL missing a scheme\r\n",
      "     --proto-redir PROTOCOLS   Enable/disable PROTOCOLS on redirect\r\n",
      " -x, --proxy [PROTOCOL://]HOST[:PORT]  Use proxy on given port\r\n",
      "     --proxy-anyauth  Pick \"any\" proxy authentication method (H)\r\n",
      "     --proxy-basic   Use Basic authentication on the proxy (H)\r\n",
      "     --proxy-digest  Use Digest authentication on the proxy (H)\r\n",
      "     --proxy-negotiate  Use HTTP Negotiate (SPNEGO) authentication on the proxy (H)\r\n",
      "     --proxy-ntlm    Use NTLM authentication on the proxy (H)\r\n",
      "     --proxy-service-name NAME  SPNEGO proxy service name\r\n",
      "     --service-name NAME  SPNEGO service name\r\n",
      " -U, --proxy-user USER[:PASSWORD]  Proxy user and password\r\n",
      "     --proxy1.0 HOST[:PORT]  Use HTTP/1.0 proxy on given port\r\n",
      " -p, --proxytunnel   Operate through a HTTP proxy tunnel (using CONNECT)\r\n",
      "     --pubkey KEY    Public key file name (SSH)\r\n",
      " -Q, --quote CMD     Send command(s) to server before transfer (F/SFTP)\r\n",
      "     --random-file FILE  File for reading random data from (SSL)\r\n",
      " -r, --range RANGE   Retrieve only the bytes within RANGE\r\n",
      "     --raw           Do HTTP \"raw\"; no transfer decoding (H)\r\n",
      " -e, --referer       Referer URL (H)\r\n",
      " -J, --remote-header-name  Use the header-provided filename (H)\r\n",
      " -O, --remote-name   Write output to a file named as the remote file\r\n",
      "     --remote-name-all  Use the remote file name for all URLs\r\n",
      " -R, --remote-time   Set the remote file's time on the local output\r\n",
      " -X, --request COMMAND  Specify request command to use\r\n",
      "     --resolve HOST:PORT:ADDRESS  Force resolve of HOST:PORT to ADDRESS\r\n",
      "     --retry NUM   Retry request NUM times if transient problems occur\r\n",
      "     --retry-delay SECONDS  Wait SECONDS between retries\r\n",
      "     --retry-max-time SECONDS  Retry only within this period\r\n",
      "     --sasl-ir       Enable initial response in SASL authentication\r\n",
      " -S, --show-error    Show error. With -s, make curl show errors when they occur\r\n",
      " -s, --silent        Silent mode (don't output anything)\r\n",
      "     --socks4 HOST[:PORT]  SOCKS4 proxy on given host + port\r\n",
      "     --socks4a HOST[:PORT]  SOCKS4a proxy on given host + port\r\n",
      "     --socks5 HOST[:PORT]  SOCKS5 proxy on given host + port\r\n",
      "     --socks5-hostname HOST[:PORT]  SOCKS5 proxy, pass host name to proxy\r\n",
      "     --socks5-gssapi-service NAME  SOCKS5 proxy service name for GSS-API\r\n",
      "     --socks5-gssapi-nec  Compatibility with NEC SOCKS5 server\r\n",
      " -Y, --speed-limit RATE  Stop transfers below RATE for 'speed-time' secs\r\n",
      " -y, --speed-time SECONDS  Trigger 'speed-limit' abort after SECONDS (default: 30)\r\n",
      "     --ssl           Try SSL/TLS (FTP, IMAP, POP3, SMTP)\r\n",
      "     --ssl-reqd      Require SSL/TLS (FTP, IMAP, POP3, SMTP)\r\n",
      " -2, --sslv2         Use SSLv2 (SSL)\r\n",
      " -3, --sslv3         Use SSLv3 (SSL)\r\n",
      "     --ssl-allow-beast  Allow security flaw to improve interop (SSL)\r\n",
      "     --ssl-no-revoke    Disable cert revocation checks (WinSSL)\r\n",
      "     --stderr FILE   Where to redirect stderr (use \"-\" for stdout)\r\n",
      "     --tcp-nodelay   Use the TCP_NODELAY option\r\n",
      " -t, --telnet-option OPT=VAL  Set telnet option\r\n",
      "     --tftp-blksize VALUE  Set TFTP BLKSIZE option (must be >512)\r\n",
      " -z, --time-cond TIME  Transfer based on a time condition\r\n",
      " -1, --tlsv1         Use >= TLSv1 (SSL)\r\n",
      "     --tlsv1.0       Use TLSv1.0 (SSL)\r\n",
      "     --tlsv1.1       Use TLSv1.1 (SSL)\r\n",
      "     --tlsv1.2       Use TLSv1.2 (SSL)\r\n",
      "     --trace FILE    Write a debug trace to FILE\r\n",
      "     --trace-ascii FILE  Like --trace, but without hex output\r\n",
      "     --trace-time    Add time stamps to trace/verbose output\r\n",
      "     --tr-encoding   Request compressed transfer encoding (H)\r\n",
      " -T, --upload-file FILE  Transfer FILE to destination\r\n",
      "     --url URL       URL to work with\r\n",
      " -B, --use-ascii     Use ASCII/text transfer\r\n",
      " -u, --user USER[:PASSWORD]  Server user and password\r\n",
      "     --tlsuser USER  TLS username\r\n",
      "     --tlspassword STRING  TLS password\r\n",
      "     --tlsauthtype STRING  TLS authentication type (default: SRP)\r\n",
      "     --unix-socket FILE    Connect through this Unix domain socket\r\n",
      " -A, --user-agent STRING  Send User-Agent STRING to server (H)\r\n",
      " -v, --verbose       Make the operation more talkative\r\n",
      " -V, --version       Show version number and quit\r\n",
      " -w, --write-out FORMAT  Use output FORMAT after completion\r\n",
      "     --xattr         Store metadata in extended file attributes\r\n",
      " -q                  Disable .curlrc (must be first parameter)\r\n"
     ]
    }
   ],
   "source": [
    "! docker run -it mydockerimage curl --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Rendiamola disponibile nel registro pubblico delle immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "! docker push mydockerimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Il registro ufficiale prende il nome di Hub:\n",
    "\n",
    "https://hub.docker.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(* un pò come il GitHub dei container Docker *)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                      DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\r\n",
      "nginx                     Official build of Nginx.                        2641      [OK]       \r\n",
      "jwilder/nginx-proxy       Automated Nginx reverse proxy for docker c...   586                  [OK]\r\n",
      "richarvey/nginx-php-fpm   Container running Nginx + PHP-FPM capable ...   176                  [OK]\r\n",
      "maxexcloo/nginx-php       Docker framework container with Nginx and ...   56                   [OK]\r\n",
      "million12/nginx-php       Nginx + PHP-FPM 5.5, 5.6, 7.0 (NG), CentOS...   53                   [OK]\r\n",
      "h3nrik/nginx-ldap         NGINX web server with LDAP/AD, SSL and pro...   25                   [OK]\r\n",
      "webdevops/php-nginx       Nginx with PHP-FPM                              19                   [OK]\r\n",
      "bitnami/nginx             Bitnami nginx Docker Image                      16                   [OK]\r\n"
     ]
    }
   ],
   "source": [
    "! docker search -s 10 nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Le mie immagini:\n",
    "https://hub.docker.com/u/pdonorio/\n",
    "- CINECA:\n",
    "https://hub.docker.com/u/cineca/\n",
    "- EUDAT:\n",
    "https://hub.docker.com/u/eudatb2safe/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Persistenza dei dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "I container perdono tutti i dati prodotti nel ciclo vitale, quando vengono rimossi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Aggiungo un file\n",
    "! docker run --rm busybox touch /tmp/justatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: /tmp/*: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# Verifico cosa abbiamo nella directory adesso\n",
    "! docker run -it busybox sh -c \"ls /tmp/*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lanciamo un database in un container. Il container viene distrutto.\n",
    "\n",
    "I dati vengono perduti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Come possiamo risolvere?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```\n",
    "# A partire da Docker 1.9+\n",
    "docker volume COMMAND\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRIVER              VOLUME NAME\r\n"
     ]
    }
   ],
   "source": [
    "! docker volume ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "! docker run -it \\\n",
    "    -v myvolume:/tmp \\\n",
    "    busybox touch /tmp/justatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRIVER              VOLUME NAME\r\n",
      "local               myvolume\r\n"
     ]
    }
   ],
   "source": [
    "! docker volume ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;0m/tmp/justatest\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! docker run -it \\\n",
    "    -v myvolume:/tmp \\\n",
    "    busybox sh -c \"ls /tmp/*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Modalità di uso del volume\n",
    "\n",
    "- Utilizzare un directory del sistema `host` come volume\n",
    "- Avviare un `data-only-container` (e.s. comando vuoto). Tutti i suoi volumi possono essere condivisi da successivi container con l'opzione `volume-from`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "Io => Corso Python => Docker => Anaconda => ....\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### La nostra prima immagine Docker per un corso (Python)\n",
    "\n",
    "https://hub.docker.com/r/cineca/scientificpy/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```Dockerfile\n",
    "FROM ubuntu:14.04\n",
    "MAINTAINER Paolo D. <p.donoriodemeo@cineca.it>\n",
    "\n",
    "##########################\n",
    "# APT\n",
    "RUN apt-get update && apt-get upgrade -y && \\\n",
    "    apt-get install -y wget curl build-essential python-dev \\\n",
    "    && apt-get clean\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```Dockerfile\n",
    "##########################\n",
    "# (mini)CONDA package manager\n",
    "RUN wget --quiet \\\n",
    "    https://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh && \\\n",
    "    bash Miniconda-latest-Linux-x86_64.sh -b -p /opt/miniconda && \\\n",
    "    rm Miniconda-latest-Linux-x86_64.sh\n",
    "ENV PATH /opt/miniconda/bin:$PATH\n",
    "RUN chmod -R a+rx /opt/miniconda\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```Dockerfile\n",
    "\n",
    "##########################\n",
    "# Install PyData modules and IPython dependencies\n",
    "RUN conda update --quiet --yes conda && \\\n",
    "    conda install --quiet --yes ipython \\\n",
    "        numpy scipy pandas matplotlib seaborn bokeh scikit-learn sympy \\\n",
    "        six pip sqlalchemy cython pyzmq statsmodels \\\n",
    "    && conda clean -y -t\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```Dockerfile\n",
    "#####################################\n",
    "# Setup and start notebook server\n",
    "VOLUME /data\n",
    "WORKDIR /data\n",
    "CMD ipython notebook --ip=0.0.0.0 --port=8000 --no-browser\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The good\n",
    "\n",
    "- Possibilità di replicare l'ambiente di esercitazione a casa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## The bad\n",
    "\n",
    "- Il tempo passato a spiegare come usare Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## The ugly\n",
    "- Copia/incolla di comandi non molto chiari (e.g. rimuovi tutti i containers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "Io => Corso Python => Docker => Anaconda => \n",
    "    Jupyter => ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[Project Jupyter](http://jupyter.org/) è nato ufficialmente nel 2014, come strumento dedicato esplicitamente ai servizi di Notebook agnostici del precedente progetto Ipthon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src='images/jupy.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<small> Per saperne di più:\n",
    "\n",
    "https://en.wikipedia.org/wiki/IPython#Project_Jupyter</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Il progetto ha un repository GitHub dedicato alle immagini Docker:\n",
    "\n",
    "https://github.com/jupyter/docker-stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "GitHub CINECA (SCAI) lectures:\n",
    "\n",
    "https://github.com/cineca-scai/lectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Slideshow dal vivo:\n",
    "\n",
    "(RISE plugin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```Dockerfile\n",
    "# Live slideshows\n",
    "WORKDIR /tmp\n",
    "RUN wget https://github.com/pdonorio/RISE/archive/master.tar.gz \\\n",
    "    && tar xvzf *.gz && cd *master && \\\n",
    "    python2 setup.py install && rm -rf /tmp/*\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Questa 'ricetta' la trovate nell wiki ufficiale per Docker del progetto Jupyter:\n",
    "\n",
    "https://github.com/jupyter/docker-stacks/wiki/Docker-Recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hub docker cineca e aggiornamento (facile) delle versioni nelle immagini:\n",
    "\n",
    "https://hub.docker.com/u/cineca/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "MapReduce, Hadoop, Spark\n",
    "\n",
    "(e immagine docker con cluster hadoop)\n",
    "\n",
    "https://hub.docker.com/r/cineca/nbsparkling/~/dockerfile/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```bash\n",
    "docker run -d \\\n",
    "    --name notebook \\\n",
    "    -e LECTURE_BRANCH=datanalytics \\\n",
    "    -e LECTURE_PATH=material \\\n",
    "    -h notebook\n",
    "    -v myvolume:/data/lectures \\\n",
    "    -p 80:8888 \\\n",
    "    cineca/nbsparkling\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "Io => Corso Python => Docker => Anaconda => \n",
    "    Jupyter => Pycon6 => ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## L'ispirazione per questo talk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='images/tweet.png' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "https://twitter.com/paolodonorio/status/589834889974919168\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Un cluster volatile di applicazioni\n",
    "Container *on demand* ovunque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://technologyconversations.files.wordpress.com/2015/11/docker-swarm.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lo *sciame*\n",
    "\n",
    "> swarm, cluster, hive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "N.B. il docker engine di default non ascolta richieste dall'esterno del nodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> By default, it will listen on unix:///var/run/docker.sock to allow only local connections by the root user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> You could set it to 0.0.0.0:2375 or a specific host IP to give access to everybody"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Passo 0\n",
    "\n",
    "Riavviare il Docker engine dei nodi che parteciperanno allo swarm per consentire l'accesso dall'esterno\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Suggerimento:* \n",
    "\n",
    "usare certificati TLS per garantire la sicurezza nell'accesso alle remote API di Docker\n",
    "\n",
    "o in alternativa consentire l'accesso alle porte dell'engine soltanto dai nodi dello swarm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Passo 1\n",
    "\n",
    "Per avviare uno *sciame* di container su più nodi, è necessario un **token**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```bash\n",
    "$ docker run swarm create\n",
    "7bbca2c4c83c32b8d9b5e501f9699d50\n",
    "\n",
    "# Questo sarà il nostro identificativo per il cluster \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Passo 2\n",
    "\n",
    "Un nodo con un Docker engine deve segnalare di voler essere lo *swarm manager*.\n",
    "\n",
    "Si mette in ascolto su una porta prescelta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```bash\n",
    "docker run -d -t \\\n",
    "    swarm manage -H 0.0.0.0:3376 \\\n",
    "    -p 3376:3376\n",
    "    # --tlsverify --tlscacert=/certs/ca.pem \\\n",
    "    # --tlscert=/certs/server.pem --tlskey=/certs/server-key.pem \\\n",
    "    token://7bbca2c4c83c32b8d9b5e501f9699d50\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Passo 3\n",
    "\n",
    "Gli altri nodi che vogliamo far partecipare al cluster di container segnalano al manager di essere slave per quel token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```bash\n",
    "$ docker run -d \\\n",
    "    swarm join \\\n",
    "    --addr=NODE_IP_SWARM_MANAGER:3376 token://7bbca2c4c83c32b8d9b5e501f9699d50\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Passo 4\n",
    "\n",
    "Fare uso del nuovo swarm con comandi analoghi a quelli per singolo nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```bash\n",
    "# Utilizzando il nome dell'ip e porta del manager, \n",
    "# possiamo accedere al cluster come se fosse un unico *Docker engine* !\n",
    "$ docker -H tcp://NODE_IP_SWARM_MANAGER:3376 ps\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://sreeninet.files.wordpress.com/2015/05/docker6.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Swarm 1.0, pronto per la produzione da novembre 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "Io => Corso Python => Docker => Anaconda => \n",
    "    Jupyter => Pycon6 => OpenStack => ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Press release su apertura ufficiale PICO\n",
    "\n",
    "28 ottobre 2014\n",
    "\n",
    "http://www.cineca.it/it/news/pico-cineca-la-nuova-piattaforma-applicazioni-di-data-analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "cit: http://www.hpc.cineca.it/hardware/pico\n",
    "\n",
    "> It is intended to enable new \"BigData\" classes of applications, related to the management and processing of large quantities of data, coming both from simulations and experiments. \n",
    "\n",
    "> Particular reference is put on all emerging scenarios as interactive model , as well as new paradigms of resource utilization through \"Cloud Computing\" technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## [Openstack](https://www.openstack.org/)\n",
    "\n",
    "(Cloud computing *infrastructure-as-a-service*, **IaaS**)\n",
    "\n",
    "è la tecnologia utilizzata su PICO per fornire accesso alle risorse dedicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Providing infrastructure means that OpenStack makes it easy for users to quickly add new instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Typically, the infrastructure then runs a \"platform\" upon which a developer can create software applications which are delivered to the end users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src='https://www.scaleuptech.com/de/wp-content/uploads/2016/02/software_diagram_os.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```bash\n",
    "# Lanciare una nuova Virtual Machine con le API di Nova nel servizio di calcolo di Openstack\n",
    "\n",
    "$ nova boot --image imageID --flavor flavorID\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ma se volessi lanciare container su una nuova VM di Openstack?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Un *telecomando* per accendere un nodo Docker su qualsiasi cloud:\n",
    "\n",
    "**Docker Machine**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```bash\n",
    "$ docker-machine create \\\n",
    " --driver openstack \\\n",
    " --openstack-ssh-user ubuntu \\\n",
    " --openstack-image-id cfb0a24a-16a5-4d19-a15b-ee29c9375d52 \\\n",
    " --openstack-flavor-name m1.small \\\n",
    " --openstack-floatingip-pool public \\\n",
    " --openstack-sec-groups default \\\n",
    " my-openstack-vm-for-docker\n",
    " \n",
    "# my-openstack-vm-for-docker sarà una VM nuova \n",
    "# che ha il docker engine installato e avviato\n",
    " \n",
    "# Nota: bisogna fornire credenziali di accesso valide \n",
    "# a un 'tenant' di Openstack che ha abbastanza risorse\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```bash\n",
    "# Accesso dal client locale al docker engine remoto creato con docker machine\n",
    "\n",
    "$ eval \"$(docker-machine env my-openstack-vm-for-docker)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='https://docs.docker.com/machine/img/provision-use-case.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "N.B. grazie a *docker machine* possiamo usare un cloud qualsiasi:\n",
    "    \n",
    "virtualbox, openstack, aws, google cloud, azure, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"http://www.extraordy.com/wp-content/uploads/2016/02/docker-machine_w_450.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "Io => Corso Python => Docker => Anaconda => \n",
    "    Jupyter => Pycon6 => OpenStack =\n",
    "        Automatizzare la creazione di \n",
    "        container Jupyter su cloud\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dicembre 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://blotterpaper.files.wordpress.com/2013/02/working-hard.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"http://cliparts101.com/files/791/0550A29FE5645D58F3EFFC50905A4EE3/Computer_Exploding.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"http://www.clipartbest.com/cliparts/9i4/ny9/9i4ny9xiE.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"http://assets4.bigthink.com/system/idea_thumbnails/59699/primary/working_late.jpg?1441892760\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "https://github.com/pdonorio/cloudscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cosa è accaduto in due settimane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> Fabric is a Python (2.5-2.7) library and command-line tool for streamlining the use of SSH for application deployment or systems administration tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plumbum, paramiko, invoke "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "demo da command line invoke -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "demo creazione containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aggiungi comando list containers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voti corso python for computing science 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/scores.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## I corsi che hanno fatto uso dei container jupyter su cloud \n",
    "(nei primi 4 mesi del progetto)\n",
    "\n",
    "- Computing science @rome\n",
    "- Massive data analytics @rome\n",
    "- Master for Big Data @bologna\n",
    "- Massive data analytics @bologna\n",
    "- Python objects and MapReduce @pisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "Io => Corso Python => Docker => Anaconda => \n",
    "    Jupyter => Pycon6 => OpenStack => \n",
    "    Il futuro => ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Il mio futuro con il Python e Docker\n",
    "\n",
    "- Roadmap \n",
    "(consul?)\n",
    "- Issues and Pull request\n",
    "- HPC EUROPA 3 - JRA su Containers\n",
    "- Flask REST HTTP API per progetto EUDAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dockerize or not to dockerize?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
